{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       textID                                               text  \\\n",
      "0  cb774db0d1                I`d have responded, if I were going   \n",
      "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
      "2  088c60f138                          my boss is bullying me...   \n",
      "3  9642c003ef                     what interview! leave me alone   \n",
      "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
      "5  28b57f3990  http://www.dothebouncy.com/smf - some shameles...   \n",
      "6  6e0c6d75b1  2am feedings for the baby are fun when he is a...   \n",
      "7  50e14c0bb8                                         Soooo high   \n",
      "8  e050245fbd                                        Both of you   \n",
      "9  fc2cbefa9d   Journey!? Wow... u just became cooler.  hehe....   \n",
      "\n",
      "                                       selected_text sentiment Time of Tweet  \\\n",
      "0                I`d have responded, if I were going   neutral       morning   \n",
      "1                                           Sooo SAD  negative          noon   \n",
      "2                                        bullying me  negative         night   \n",
      "3                                     leave me alone  negative       morning   \n",
      "4                                      Sons of ****,  negative          noon   \n",
      "5  http://www.dothebouncy.com/smf - some shameles...   neutral         night   \n",
      "6                                                fun  positive       morning   \n",
      "7                                         Soooo high   neutral          noon   \n",
      "8                                        Both of you   neutral         night   \n",
      "9                       Wow... u just became cooler.  positive       morning   \n",
      "\n",
      "  Age of User              Country  Population -2020  Land Area (Km²)  \\\n",
      "0        0-20          Afghanistan          38928346         652860.0   \n",
      "1       21-30              Albania           2877797          27400.0   \n",
      "2       31-45              Algeria          43851044        2381740.0   \n",
      "3       46-60              Andorra             77265            470.0   \n",
      "4       60-70               Angola          32866272        1246700.0   \n",
      "5      70-100  Antigua and Barbuda             97929            440.0   \n",
      "6        0-20            Argentina          45195774        2736690.0   \n",
      "7       21-30              Armenia           2963243          28470.0   \n",
      "8       31-45            Australia          25499884        7682300.0   \n",
      "9       46-60              Austria           9006398          82400.0   \n",
      "\n",
      "   Density (P/Km²)  \n",
      "0               60  \n",
      "1              105  \n",
      "2               18  \n",
      "3              164  \n",
      "4               26  \n",
      "5              223  \n",
      "6               17  \n",
      "7              104  \n",
      "8                3  \n",
      "9              109  \n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('sentences/train.csv',encoding='latin1')\n",
    "test_df = pd.read_csv('sentences/test.csv',encoding='latin1')\n",
    "print(train_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehot_encoder_sentiment=OneHotEncoder()\n",
    "train_Y=onehot_encoder_sentiment.fit_transform(train_df[['sentiment']]).toarray()\n",
    "test_Y=onehot_encoder_sentiment.fit_transform(test_df[['sentiment']]).toarray()\n",
    "\n",
    "print(train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y_df = pd.DataFrame(train_Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['selected_text'] = train_df['selected_text'].fillna('').astype(str)\n",
    "train_df['text'] = train_df['text'].fillna('').astype(str)\n",
    "\n",
    "test_df['selected_text'] = train_df['selected_text'].fillna('').astype(str)\n",
    "test_df['text'] = train_df['text'].fillna('').astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      " 420  72]\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import json\n",
    "\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "\n",
    "## Define the vocabulary size\n",
    "voc_size=10000\n",
    "\n",
    "max_sentence_length=128\n",
    "tokenizer = Tokenizer(num_words=voc_size, oov_token=\"<OOV>\")  # Limit vocabulary size\n",
    "\n",
    "tokenizer.fit_on_texts(train_df['selected_text'])  # Fit tokenizer on training data\n",
    "\n",
    "# Encode the training and test data\n",
    "encoded_train = tokenizer.texts_to_sequences(train_df['selected_text'])\n",
    "encoded_test = tokenizer.texts_to_sequences(test_df['selected_text'])\n",
    "\n",
    "train_X=pad_sequences(encoded_train,padding='pre',maxlen=max_sentence_length)\n",
    "test_X =pad_sequences(encoded_test,padding='pre',maxlen=max_sentence_length)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# Save word index\n",
    "with open('word_index.json', 'w') as f:\n",
    "    json.dump(word_index, f)\n",
    "print(train_X[1])\n",
    "print(len(train_X[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 128, 128)          1280000   \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 128)               131584    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1411971 (5.39 MB)\n",
      "Trainable params: 1411971 (5.39 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=voc_size, output_dim=128, input_length=128))  # Embedding layer\n",
    "model.add(LSTM(128, return_sequences=False))  # LSTM layer\n",
    "model.add(Dense(3, activation='sigmoid'))  # Output layer for binary classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create an instance of EarlyStoppping Callback\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "earlystopping=EarlyStopping(monitor='val_loss',patience=5,restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "687/687 [==============================] - 43s 60ms/step - loss: 0.5539 - accuracy: 0.7770 - val_loss: 0.4423 - val_accuracy: 0.8361\n",
      "Epoch 2/10\n",
      "687/687 [==============================] - 46s 67ms/step - loss: 0.3408 - accuracy: 0.8765 - val_loss: 0.4271 - val_accuracy: 0.8432\n",
      "Epoch 3/10\n",
      "687/687 [==============================] - 51s 74ms/step - loss: 0.2595 - accuracy: 0.9073 - val_loss: 0.4651 - val_accuracy: 0.8268\n",
      "Epoch 4/10\n",
      "687/687 [==============================] - 53s 77ms/step - loss: 0.2131 - accuracy: 0.9239 - val_loss: 0.5061 - val_accuracy: 0.8295\n",
      "Epoch 5/10\n",
      "687/687 [==============================] - 52s 76ms/step - loss: 0.1729 - accuracy: 0.9390 - val_loss: 0.5345 - val_accuracy: 0.8288\n",
      "Epoch 6/10\n",
      "687/687 [==============================] - 55s 80ms/step - loss: 0.1402 - accuracy: 0.9493 - val_loss: 0.6101 - val_accuracy: 0.8266\n",
      "Epoch 7/10\n",
      "687/687 [==============================] - 56s 82ms/step - loss: 0.1149 - accuracy: 0.9580 - val_loss: 0.6421 - val_accuracy: 0.8148\n"
     ]
    }
   ],
   "source": [
    "## Train the model with early sstopping\n",
    "history=model.fit(\n",
    "    train_X,train_Y,epochs=10,batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[earlystopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\noams\\Desktop\\MyProjects\\SentimentAnalysis\\myEnv\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "## Save model file\n",
    "model.save('LSTM_sentiment_analysis.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def sentiment_predict(sentence):\n",
    "    categories_map = {0:'negative' , 1:'neutral' , 2:'positive'}\n",
    "    \n",
    "    myEncoder = tokenizer.texts_to_sequences([sentence])\n",
    "    print(myEncoder)\n",
    "    padded_input=pad_sequences(myEncoder,padding='pre',maxlen=max_sentence_length)\n",
    "    #print(padded_input)\n",
    "    prediction=model.predict(padded_input)\n",
    "    print(prediction)\n",
    "    print('The sentiment is',categories_map[np.argmax(prediction)],'With probability of ',np.max(prediction),'%')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[70, 180]]\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "[[0.04236572 0.17972253 0.9840737 ]]\n",
      "The sentiment is positive With probability of  0.9840737 %\n"
     ]
    }
   ],
   "source": [
    "example_review = \"Its amazing\"\n",
    "\n",
    "sentiment_predict(example_review)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
